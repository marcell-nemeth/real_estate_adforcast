{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adatok beolvasása"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"training.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#It is not worth it everywhere\n",
    "def categorial_without_missing_handling(df, column):\n",
    "    df = pd.get_dummies(df, columns=[column])\n",
    "    return df\n",
    "\n",
    "def categorial_with_missing_handling(df, column):\n",
    "    df[column + '_missing'] = df[column].isnull()\n",
    "    df[column] = df[column].fillna(df[column].mode()[0])\n",
    "    df = pd.get_dummies(df, columns=[column])\n",
    "    return df\n",
    "\n",
    "def categorial_values(df):\n",
    "    df = categorial_without_missing_handling(df, \"city\")\n",
    "    df = categorial_with_missing_handling(df, \"property_subtype\")\n",
    "    df = categorial_without_missing_handling(df, \"view_type\")\n",
    "    df = categorial_with_missing_handling(df, \"orientation\")\n",
    "    df = categorial_without_missing_handling(df, \"garden_access\")\n",
    "    df = categorial_without_missing_handling(df, \"heating_type\")\n",
    "    df = categorial_with_missing_handling(df, \"elevator_type\")\n",
    "    \n",
    "    #Did not helped\n",
    "    #df.loc[df.property_condition_type != 'missing_info', \"property_condition_type_missing_info\"] = 0\n",
    "    #df.loc[df.property_condition_type == 'missing_info', \"property_condition_type_missing_info\"] = 1\n",
    "    #df.loc[df.property_condition_type == 'missing_info', \"property_condition_type\"] = \"good\"\n",
    "    df = categorial_without_missing_handling(df, \"property_condition_type\")\n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clear_non_scalar_value(df, property, value, replace):\n",
    "    df_clean = df.loc[df[property] == value, property] = replace\n",
    "    return df\n",
    "\n",
    "def fill_missing_numeric_values(df):\n",
    "    df[\"small_room_cnt\"] = df[\"small_room_cnt\"].fillna(0)\n",
    "\n",
    "    df[\"balcony_area\"] = df[\"balcony_area\"].fillna(0)\n",
    "\n",
    "    df[\"building_floor_count\"] = df[\"building_floor_count\"].fillna(0)\n",
    "    df = clear_non_scalar_value(df, \"building_floor_count\", 'more than 10', 11)\n",
    "\n",
    "    df[\"property_floor\"] = df[\"property_floor\"].fillna(0)\n",
    "    df = clear_non_scalar_value(df, 'property_floor', 'ground floor', 0)\n",
    "    df = clear_non_scalar_value(df, 'property_floor', 'mezzanine floor', 0.5)\n",
    "    df = clear_non_scalar_value(df, 'property_floor', 'basement', -1.0)\n",
    "    df = clear_non_scalar_value(df, 'property_floor', '10 plus', 11)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_new_datas(df):\n",
    "    df['sm_price'] = df['price_created_at'] / df['property_area']\n",
    "    df = df.replace([np.inf, -np.inf], np.nan)\n",
    "    df['sm_price'] = df['sm_price'].fillna(0)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# None of this helped\n",
    "def cut_irreal_values(df):\n",
    "    #df['price_created_at'] = np.clip(df['price_created_at'],1,1000)\n",
    "    #df['balcony_area'] = np.clip(df['balcony_area'],0,25)\n",
    "    #df['room_cnt'] = np.clip(df['room_cnt'],0,8)\n",
    "    #df['small_room_cnt'] = np.clip(df['small_room_cnt'],0,6)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def delete_unimportant_data(df):\n",
    "    df = df.drop(\"county\", axis=1)\n",
    "    df = df.drop(\"property_type\", axis=1)\n",
    "    df = df.drop(\"postcode\", axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clear_dataframe(df):\n",
    "    df = fill_missing_numeric_values(df)\n",
    "    df = categorial_values(df)\n",
    "    df = create_new_datas(df)\n",
    "    #df = cut_irreal_values(df)\n",
    "    df = delete_unimportant_data(df)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = clear_dataframe(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_features = df.columns.tolist()\n",
    "input_features.remove('ad_view_cnt')\n",
    "input_features.remove('id')\n",
    "\n",
    "target = 'ad_view_cnt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: STRATIFY\n",
    "train, test = train_test_split(df, train_size=0.8, test_size=0.2, random_state=42)\n",
    "\n",
    "#skf = StratifiedKFold(n_splits=5, random_state=242)\n",
    "#for train_idx, test_idx in skf.split(df, df.ad_view_cnt):\n",
    "#    X_train, y_train = df.loc[train_idx, input_features], df.loc[train_idx, target]\n",
    "#    X_test, y_test = df.loc[test_idx, input_features], df.loc[test_idx, target]\n",
    "#    print(\n",
    "#        \"{:5d} {:5d} {:5d} {:5d} {:.4f} {:.4f} {:1d}\".format(\n",
    "#            X_train.shape[0], X_test.shape[0], \n",
    "#            y_train.shape[0], y_test.shape[0], \n",
    "#            y_train.mean(), y_test.mean(),\n",
    "#            len(set(y_train.index) & set(y_test.index))\n",
    "#        )\n",
    "#    )\n",
    "\n",
    "X_train = train[input_features]\n",
    "y_train = train[target]\n",
    "X_test = test[input_features]\n",
    "y_test = test[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "std_scale = StandardScaler().fit(X_train)\n",
    "X_train = std_scale.transform(X_train)\n",
    "X_test = std_scale.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#rf = RandomForestRegressor(n_estimators=50, max_depth=10, random_state=431)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#rf = rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#yhat_test = pd.Series(rf.predict(X_test), index=y_test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gb = GradientBoostingRegressor(n_estimators=900, learning_rate=0.01, max_depth=11, random_state=431)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gb = gb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_test = pd.Series(gb.predict(X_test), index=y_test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kiértékelés"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final test and export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reading the input\n",
    "df_train = pd.read_csv(\"training.csv\")\n",
    "df_test = pd.read_csv(\"testing.csv\")\n",
    "\n",
    "#Data cleaning\n",
    "df_train = clear_dataframe(df_train)\n",
    "df_test = clear_dataframe(df_test)\n",
    "\n",
    "#Features\n",
    "X_train = df_train[input_features]\n",
    "y_train = df_train[target]\n",
    "X_test = df_test[input_features]\n",
    "\n",
    "#Standardization\n",
    "std_scale = StandardScaler().fit(X_train)\n",
    "X_train = std_scale.transform(X_train)\n",
    "X_test = std_scale.transform(X_test)\n",
    "\n",
    "gb = gb.fit(X_train, y_train)\n",
    "final_result = pd.DataFrame(gb.predict(X_test), columns=['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_result = np.clip(final_result,0,1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_result.insert(0, 'id', df_test.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_result.to_csv('f2avxh.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
